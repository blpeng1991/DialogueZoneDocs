


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Creating an Agent &mdash; dialoge zone  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="tasktk package" href="../tasktk.html" />
    <link rel="prev" title="Welcome to dialoge zone’s documentation!" href="../index.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://blpeng1991.github.io/DialogueZone/">Get Started</a>
          </li>

          <!-- <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/features">Features</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/blog/">Blog</a>
          </li> -->

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/index.html">Docs</a>
          </li>

          

          <li>
            <a href="https://github.com/xiul-msr/DialogueZone">Github</a>
          </li>

          <li>
            <a href="maito:">Contact</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Creating an Agent</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.html">tasktk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.dialog_agent.html">tasktk.dialog_agent package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.dst.html">tasktk.dst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nlg.html">tasktk.nlg package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nlg.multiwoz_template_nlg.html">tasktk.nlg.multiwoz_template_nlg package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nlu.html">tasktk.nlu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nlu.mlst.html">tasktk.nlu.mlst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nrg.html">tasktk.nrg package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nrg.mdrg.html">tasktk.nrg.mdrg package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nrg.mdrg.model.html">tasktk.nrg.mdrg.model package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.nrg.mdrg.utils.html">tasktk.nrg.mdrg.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.policy.html">tasktk.policy package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.policy.system.html">tasktk.policy.system package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.policy.system.qlearning.html">tasktk.policy.system.qlearning package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.policy.user.html">tasktk.policy.user package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.usr.html">tasktk.usr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.usr.s2s_usr.html">tasktk.usr.s2s_usr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.usr.uber_usr.html">tasktk.usr.uber_usr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasktk.util.html">tasktk.util package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Creating an Agent</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/seq2seq_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="creating-an-agent">
<h1>Creating an Agent<a class="headerlink" href="#creating-an-agent" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: Alexander Holden Miller</p>
<p>In this tutorial, we’ll be setting up an agent which learns from the data it
sees to produce the right answers.</p>
<p>For this agent, we’ll be implementing a simple GRU Seq2Seq agent based on
Sequence to Sequence Learning with Neural Networks (Sutskever et al. 2014) and
Sean Robertson’s <a class="reference external" href="http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">Seq2Seq PyTorch tutorial</a>.</p>
<div class="section" id="part-1-naming-things">
<h2>Part 1: Naming Things<a class="headerlink" href="#part-1-naming-things" title="Permalink to this headline">¶</a></h2>
<p>In order to make programmatic importing easier, we use a simple naming scheme
for our models, so that on the command line we can just type “–model seq2seq”
to load up the seq2seq model.</p>
<p>To this end, we create a folder under parlai/agents with the name seqseq, and
then put an empty __init__.py file there along with seq2seq.py.
Then, we name our agent “Seq2seqAgent”.</p>
<p>This way, “–model seq2seq” can translate to “parlai.agents.seq2seq.seq2seq:Seq2seqAgent”.
Underscores in the name become capitals in the class name: “–model local_human”
resides at “parlai.agents.local_human.local_human:LocalHumanAgent”.
If you need to put a model at a different path, you can specify the full path
on the command line in the format above (with a colon in front of the class name).
For example, “–model parlai.agents.remote_agent.remote_agent:ParsedRemoteAgent”.</p>
</div>
<div class="section" id="part-2-main-agent-methods">
<h2>Part 2: Main Agent Methods<a class="headerlink" href="#part-2-main-agent-methods" title="Permalink to this headline">¶</a></h2>
<p>First off, generally we should inherit from the Agent class in parlai.core.agents.
This provides us with some default implementations (often, <code class="docutils literal notranslate"><span class="pre">pass</span></code>) of some utility
functions like “shutdown”.</p>
<p>First let’s focus on the primary functions to implement: <code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">observe</span></code>, and <code class="docutils literal notranslate"><span class="pre">act</span></code>.</p>
<p>The standard initialization parameters for agents are a dict of command-line parameters <cite>opt</cite>
and an optional dict of shared parameters called <cite>shared</cite>.</p>
<p>For our Seq2Seq model we’ll call our parent init method, which does a few basic operations
like setting self.observation to None and creating a deep copy of the <cite>opt</cite> dict.</p>
<p>Then, we do a check to see if the <cite>shared</cite> parameter is set.
When it is not None, it’s telling this instance to initialize with this particular
state, as this instance will be used either for batched or hogwild training
(depending on your preference). We’ll take a quick digression to describe how
batching is set up.</p>
<div class="section" id="batching-example">
<h3>Batching Example<a class="headerlink" href="#batching-example" title="Permalink to this headline">¶</a></h3>
<p>Let’s say we are training our seq2seq model on <cite>babi:task10k:1</cite>. What happens
behind the scenes for a batch size of 4 is that we actually create four shared
versions of the bAbI Task10k teacher, and four shared versions of the seq2seq
agent. These shared versions are initialized from the originals: for the bAbI
teachers, they inherit the data from their parent agent, but they each have
their own local state such as the current example they’re showing or how far
through a bAbI episode they are (bAbI task 1 has five examples per episode).
For the seq2seq agent, each shared agent is keeping track of the previous
examples they’ve seen in this same episode, since each observation does not
repeat previously seen but related information–the agent has to remember it.</p>
<p>For example, in the first example the agent could get something like the following:
“John is in the bathroom. Mary is in the kitchen. Where is Mary?”
And in the second example in the episode, the agent could get:
“Mary picked up the milk. Mary went to the hallway. Where is John?”
Here, the answer is in the first example’s context, so the agent had to remember it.</p>
<p>Observations are generated by calling the <code class="docutils literal notranslate"><span class="pre">act</span></code> function on each teacher, then
passing those observations to each agent by calling the <code class="docutils literal notranslate"><span class="pre">observe</span></code> function of the
shared agents. The agents are free to transform the previous observation
(for example, prepending previously seen text from the same episode, if applicable).
These transformed observations are packed into a list, which is then passed to
<code class="docutils literal notranslate"><span class="pre">batch_act</span></code> function our agent implements. We can implement <code class="docutils literal notranslate"><span class="pre">batch_act</span></code> differently
from the simple <code class="docutils literal notranslate"><span class="pre">act</span></code> function to take advantage of the effects of batching
over multiple examples when executing or updating our model.</p>
<p>Thus, since our  agent’s shared-instances will only be used to keep track
of state particular to their sequence of examples in the batch, we have
barely anything to do when setting these shared instances up: we just initialize the
<code class="docutils literal notranslate"><span class="pre">self.episodeDone</span></code> flag so we know whether we are in the middle of an episode or not.</p>
<p>The full initialization of the model is included further below, but is very
particular to this particular implementation. Let’s talk more about the primary
agent functions we need to define first.</p>
</div>
<div class="section" id="observing-and-acting">
<h3>Observing and Acting<a class="headerlink" href="#observing-and-acting" title="Permalink to this headline">¶</a></h3>
<p>Let’s take a look at the <code class="docutils literal notranslate"><span class="pre">observe</span></code> function. Here, we can modify the
observation dict if necessary, and then return it to be queued for batching.</p>
<p>In this version, we first make a deep copy of the observation. Then, if this is
not the first entry in an episode (some datasets like SQuAD have only one entry
for every episode, but others like bAbI have multiple), then we prepend the
previous text to the current text. We use a newline to separate them in case the
model wants to recognize the difference between different lines.</p>
<p>Then, we store whether this is the last entry in the episode so that we’ll be
ready to reset next time if we need to.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">observe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_done</span><span class="p">:</span>
        <span class="c1"># if the last example wasn&#39;t the end of an episode, then we need to</span>
        <span class="c1"># recall what was said in that example</span>
        <span class="n">prev_dialogue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
        <span class="n">observation</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_dialogue</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">observation</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="n">observation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">episode_done</span> <span class="o">=</span> <span class="n">observation</span><span class="p">[</span><span class="s1">&#39;episode_done&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">observation</span>
</pre></div>
</div>
<p>Next up is the <code class="docutils literal notranslate"><span class="pre">act</span></code> function. Since we are going to implement a batched
version, we’ll just call the batched version from our single-example act to
reduce code duplication. The performance hit here won’t matter much since we’ll
only use a batch size of one when debugging.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># call batch_act with this batch of one</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_act</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Now it’s time for the batch_act function. This function gets a list of length
batchsize of observations and returns a list of the same length with this
agent’s replies.</p>
<p>We’ll follow this loose format:</p>
<ol class="arabic simple">
<li>Set up our list of dicts to send back as replies, with the agent’s ID set.</li>
<li>Convert the incoming observations into tensors to feed into our model.</li>
<li>Produce predictions on the input text using the model. If labels were provided, update the model as well.</li>
<li>Unpack the predictions into the reply dicts and return them.</li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">batch_act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">):</span>
    <span class="n">batchsize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
    <span class="c1"># initialize a table of replies with this agent&#39;s id</span>
    <span class="n">batch_reply</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">getID</span><span class="p">()}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchsize</span><span class="p">)]</span>

    <span class="c1"># convert the observations into batches of inputs and targets</span>
    <span class="c1"># valid_inds tells us the indices of all valid examples</span>
    <span class="c1"># e.g. for input [{}, {&#39;text&#39;: &#39;hello&#39;}, {}, {}], valid_inds is [1]</span>
    <span class="c1"># since the other three elements had no &#39;text&#39; field</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">valid_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchify</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># no valid examples, just return the empty responses we set up</span>
        <span class="k">return</span> <span class="n">batch_reply</span>

    <span class="c1"># produce predictions either way, but use the targets if available</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)):</span>
        <span class="c1"># map the predictions back to non-empty examples in the batch</span>
        <span class="c1"># we join with spaces since we produce tokens one at a time</span>
        <span class="n">batch_reply</span><span class="p">[</span><span class="n">valid_inds</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">EOS</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">batch_reply</span>
</pre></div>
</div>
<p>Since the implementation of <code class="docutils literal notranslate"><span class="pre">batchify</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> are particular to our
model, we’ll table those for now. Next up, we’ll cover some of
the other methods in the Agent API.</p>
</div>
</div>
<div class="section" id="part-3-extended-agent-api">
<h2>Part 3: Extended Agent API<a class="headerlink" href="#part-3-extended-agent-api" title="Permalink to this headline">¶</a></h2>
<p>There are a few other useful methods you may want to define in your agent to
take of additional functionality one might want during training. Many of these
functions will be automatically called if you use our example training function
to train your model.</p>
<div class="section" id="share">
<h3>share()<a class="headerlink" href="#share" title="Permalink to this headline">¶</a></h3>
<p>Agents can use this method to share any information they might want between
different instances during batching or hogwild training. For example, during
hogwild training all models are being trained indepedently in multiple processes,
so you would want to share the model parameters between each one. Teacher classes
use this method to share their data and metrics with other shared intances.</p>
<p>If you define this method, it’s usually a good idea to initialize the shared
dict that’s begin return by calling super().share() first. For example, the
Teacher class in parlai.core.agents defines it this way:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">share</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;In addition to default Agent shared parameters, share metrics.&quot;&quot;&quot;</span>
    <span class="n">shared</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">share</span><span class="p">()</span>
    <span class="n">shared</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span>
    <span class="k">return</span> <span class="n">shared</span>
</pre></div>
</div>
</div>
<div class="section" id="shutdown">
<h3>shutdown()<a class="headerlink" href="#shutdown" title="Permalink to this headline">¶</a></h3>
<p>This function allows your model to do any final wrapup, such as writing any last
logging info, saving an end-state version of the model if desired, or closing
any open connections.</p>
<p>Our seq2seq model doesn’t implement this, but the agents in parlai/agents/remote_agent
use this to close their open TCP connection after sending a shutdown signal through.</p>
</div>
</div>
<div class="section" id="part-4-finishing-the-seq2seq-model">
<h2>Part 4: Finishing the Seq2Seq model<a class="headerlink" href="#part-4-finishing-the-seq2seq-model" title="Permalink to this headline">¶</a></h2>
<p>Here we’ll take a look at the full details of <code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">batchify</span></code>, <code class="docutils literal notranslate"><span class="pre">predict</span></code>, and more.</p>
<div class="section" id="full-init">
<h3>Full __init__()<a class="headerlink" href="#full-init" title="Permalink to this headline">¶</a></h3>
<p>Here’s the full code to get the initialization of our model working.
While you might define the model as a separate class if you prefer,
we’re going to define its modules in-line here, since it’s such a simple model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Seq2seqAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">shared</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c1"># initialize defaults first</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">shared</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">shared</span><span class="p">:</span>
            <span class="c1"># this is not a shared instance of this class, so do full</span>
            <span class="c1"># initialization. if shared is set, only set up shared members.</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">dict</span> <span class="o">=</span> <span class="n">DictionaryAgent</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="s1">&#39;Seq2Seq&#39;</span>
            <span class="c1"># we use EOS markers to break input and output and end our output</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">EOS</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dict</span><span class="o">.</span><span class="n">eos_token</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">EOS</span><span class="p">,</span> <span class="s1">&#39;episode_done&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">EOS_TENSOR</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dict</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">EOS</span><span class="p">))</span>

            <span class="c1"># store important params directly</span>
            <span class="n">hsz</span> <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;hiddensize&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hsz</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;numlayers&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;learningrate&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">longest_label</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># set up modules</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="c1"># lookup table stores word embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dict</span><span class="p">),</span> <span class="n">hsz</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                   <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="c1"># encoder captures the input text</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">hsz</span><span class="p">,</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;numlayers&#39;</span><span class="p">])</span>
            <span class="c1"># decoder produces our output states</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="n">hsz</span><span class="p">,</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;numlayers&#39;</span><span class="p">])</span>
            <span class="c1"># linear layer helps us produce outputs from final decoder state</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">h2o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hsz</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dict</span><span class="p">))</span>
            <span class="c1"># droput on the linear layer helps us generalize</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="s1">&#39;dropout&#39;</span><span class="p">])</span>
            <span class="c1"># softmax maps output scores to probabilities</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">()</span>

            <span class="c1"># set up optims for each module</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">opt</span><span class="p">[</span><span class="s1">&#39;learningrate&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optims</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;lt&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lt</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span>
                <span class="s1">&#39;encoder&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span>
                <span class="s1">&#39;decoder&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span>
                <span class="s1">&#39;h2o&#39;</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h2o</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span>
            <span class="p">}</span>

            <span class="c1"># check for cuda</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">opt</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;no_cuda&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;[ Using CUDA ]&#39;</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">opt</span><span class="p">[</span><span class="s1">&#39;gpu&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">episode_done</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</div>
<div class="section" id="batchify">
<h3>batchify()<a class="headerlink" href="#batchify" title="Permalink to this headline">¶</a></h3>
<p>The batchify function takes in a list of observations and turns them into
tensors to use with our model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">batchify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert a list of observations into input &amp; target tensors.&quot;&quot;&quot;</span>
    <span class="c1"># valid examples</span>
    <span class="n">exs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ex</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">observations</span> <span class="k">if</span> <span class="s1">&#39;text&#39;</span> <span class="ow">in</span> <span class="n">ex</span><span class="p">]</span>
    <span class="c1"># the indices of the valid (non-empty) tensors</span>
    <span class="n">valid_inds</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ex</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span> <span class="k">if</span> <span class="s1">&#39;text&#39;</span> <span class="ow">in</span> <span class="n">ex</span><span class="p">]</span>

    <span class="c1"># set up the input tensors</span>
    <span class="n">batchsize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">exs</span><span class="p">)</span>
    <span class="c1"># tokenize the text</span>
    <span class="n">parsed</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">exs</span><span class="p">]</span>
    <span class="n">max_x_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">parsed</span><span class="p">])</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">max_x_len</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># pack the data to the right side of the tensor for this model</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">parsed</span><span class="p">):</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">max_x_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">async</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>

    <span class="c1"># set up the target tensors</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="s1">&#39;labels&#39;</span> <span class="ow">in</span> <span class="n">exs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="c1"># randomly select one of the labels to update on, if multiple</span>
        <span class="c1"># append EOS to each label</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">EOS</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">exs</span><span class="p">]</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
        <span class="n">max_y_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">parsed</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">max_y_len</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">parsed</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="n">ys</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
            <span class="n">ys</span> <span class="o">=</span> <span class="n">ys</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">async</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">valid_inds</span>
</pre></div>
</div>
</div>
<div class="section" id="predict">
<h3>predict()<a class="headerlink" href="#predict" title="Permalink to this headline">¶</a></h3>
<p>The predict function returns an output from our model. If the targets are
provided, then it also updates the model. The predictions will be biased in
this case, since we condition each token on the true label token, but we are
okay with that–it just improves training F1 scores.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Produce a prediction from our model. Update the model using the</span>
<span class="sd">    targets if available.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batchsize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>

    <span class="c1"># first encode context</span>
    <span class="n">xes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">bsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="n">h0</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">async</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">h0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
    <span class="n">_output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">xes</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

    <span class="c1"># next we use EOS as an input to kick off our decoder</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">EOS_TENSOR</span><span class="p">)</span>
    <span class="n">xe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xes</span> <span class="o">=</span> <span class="n">xe</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">xe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">xe</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># list of output tokens for each example in the batch</span>
    <span class="n">output_lines</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchsize</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">ys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># update the model based on the labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># keep track of longest label we&#39;ve ever seen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">longest_label</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">longest_label</span><span class="p">,</span> <span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">xes</span><span class="p">,</span> <span class="n">hn</span><span class="p">)</span>
            <span class="n">preds</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_idx</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">ys</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># use the true token as the next input instead of predicted</span>
            <span class="c1"># this produces a biased prediction but better training</span>
            <span class="n">xes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchsize</span><span class="p">):</span>
                <span class="c1"># convert the output scores to tokens</span>
                <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v2t</span><span class="p">([</span><span class="n">preds</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">output_lines</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_params</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># just produce a prediction without training the model</span>
        <span class="n">done</span> <span class="o">=</span> <span class="p">[</span><span class="bp">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchsize</span><span class="p">)]</span>
        <span class="n">total_done</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_len</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span><span class="p">(</span><span class="n">total_done</span> <span class="o">&lt;</span> <span class="n">batchsize</span><span class="p">)</span> <span class="ow">and</span> <span class="n">max_len</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">longest_label</span><span class="p">:</span>
            <span class="c1"># keep producing tokens until we hit EOS or max length for each</span>
            <span class="c1"># example in the batch</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">xes</span><span class="p">,</span> <span class="n">hn</span><span class="p">)</span>
            <span class="n">preds</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_idx</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">xes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
            <span class="n">max_len</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batchsize</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">[</span><span class="n">b</span><span class="p">]:</span>
                    <span class="c1"># only add more tokens for examples that aren&#39;t done yet</span>
                    <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v2t</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">EOS</span><span class="p">:</span>
                        <span class="c1"># if we produced EOS, we&#39;re done</span>
                        <span class="n">done</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
                        <span class="n">total_done</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">output_lines</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output_lines</span>
</pre></div>
</div>
</div>
<div class="section" id="hidden-to-idx">
<h3>hidden_to_idx()<a class="headerlink" href="#hidden-to-idx" title="Permalink to this headline">¶</a></h3>
<p>Finally, this function converts our hidden state (from the decoder) to specific
indices into our dictionary, allowing us to return tokens from the dictionary.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hidden_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts hidden state vectors into indices into the dictionary.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">hidden</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;bad dimensions of tensor:&#39;</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">d2o</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">drop</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">_max_score</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">idx</span><span class="p">,</span> <span class="n">scores</span>
</pre></div>
</div>
<p>For other utility functions like loading from file, or to see any new features
that we may have added to the model such as attention over the input or ranking
candidates, check out the source code at parlai/agents/seq2seq.</p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tasktk.html" class="btn btn-neutral float-right" title="tasktk package" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="Welcome to dialoge zone’s documentation!" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Microsoft.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Pytorch Sphinx</a> using a <a href="https://github.com/pytorch/pytorch_sphinx_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs and Facebook</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Creating an Agent</a><ul>
<li><a class="reference internal" href="#part-1-naming-things">Part 1: Naming Things</a></li>
<li><a class="reference internal" href="#part-2-main-agent-methods">Part 2: Main Agent Methods</a><ul>
<li><a class="reference internal" href="#batching-example">Batching Example</a></li>
<li><a class="reference internal" href="#observing-and-acting">Observing and Acting</a></li>
</ul>
</li>
<li><a class="reference internal" href="#part-3-extended-agent-api">Part 3: Extended Agent API</a><ul>
<li><a class="reference internal" href="#share">share()</a></li>
<li><a class="reference internal" href="#shutdown">shutdown()</a></li>
</ul>
</li>
<li><a class="reference internal" href="#part-4-finishing-the-seq2seq-model">Part 4: Finishing the Seq2Seq model</a><ul>
<li><a class="reference internal" href="#full-init">Full __init__()</a></li>
<li><a class="reference internal" href="#batchify">batchify()</a></li>
<li><a class="reference internal" href="#predict">predict()</a></li>
<li><a class="reference internal" href="#hidden-to-idx">hidden_to_idx()</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script type="text/javascript" src="../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  
  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/blog/">Blog</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/index.html">Docs</a>
          </li>

          <li>
            <a href="https://blpeng1991.github.com/DialogueZoneDocs/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/xiul-msr/DialogueZone">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>